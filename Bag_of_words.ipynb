{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Bag_of_words.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshnaVirdikar/Internship_files/blob/main/Bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otynSaXfNKx5"
      },
      "source": [
        "#ASHNA'S CODE USING BAG OF WORDS MODEL FOR NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7AzmjGEJuKf"
      },
      "source": [
        "#Importing libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjfE7TqIEd1S"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re \n",
        "import wordcloud\n",
        "import matplotlib\n",
        "from textblob import TextBlob\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aigZuNzrJ4IV"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ7DZrmpEd11"
      },
      "source": [
        "\n",
        "data= pd.read_csv('Tweet_global_warming.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyf7Ki5hrC_E"
      },
      "source": [
        "# to ignore jupytr notebook mein warnings!\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4-alqs3J8js"
      },
      "source": [
        "#Exploratory Data Analysis - intuition abt dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tdunp9LrJ8j",
        "outputId": "734039d3-ae97-408d-c364-6a9f98a92bdc"
      },
      "source": [
        "\r\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6090 entries, 0 to 6089\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   tweet       6090 non-null   object \n",
            " 1   existence   4225 non-null   object \n",
            " 2   confidence  6087 non-null   float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 142.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugh5sVylrWSn",
        "outputId": "9450ea21-e9b1-4258-a1b5-a49d5f66d9a2"
      },
      "source": [
        "data['existence'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Y      2554\n",
              "N      1053\n",
              "Yes     557\n",
              "No       61\n",
              "Name: existence, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZs3p7Zwray6",
        "outputId": "ca769d2d-1529-4232-90d0-d771c6e3746b"
      },
      "source": [
        "data['confidence'].min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3346"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP4-OW0Crdmi",
        "outputId": "3f9e70ac-3cf5-40db-980d-a1546c520f59"
      },
      "source": [
        "data['confidence'].max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srev4Hk6Ed17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ea1afa-3573-42e7-8dd6-70ada3cdce25"
      },
      "source": [
        "#to check the total number of rows that have duplicate values\n",
        "data.duplicated().sum() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAOobvO7Ed19"
      },
      "source": [
        "# dropping duplicate values \n",
        "data=data.drop_duplicates (keep = 'first',inplace=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opYljogyEd1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b09373cf-9dab-42d4-d326-a71ed6bf4149"
      },
      "source": [
        "#Checking for missing values \n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet            0\n",
              "existence     1829\n",
              "confidence       3\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq9z66f79JPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8aa27c-0b64-426e-c1de-1d5c1990715c"
      },
      "source": [
        "#dropping missing values \r\n",
        "data=data.dropna(axis=0,how='any') \r\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4134 entries, 0 to 6089\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   tweet       4134 non-null   object \n",
            " 1   existence   4134 non-null   object \n",
            " 2   confidence  4134 non-null   float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 129.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8u8JGchKE2l"
      },
      "source": [
        "# Cleaning the texts for sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncjVHGpWEd2D"
      },
      "source": [
        "\n",
        "# Created a new columns i.e. clean_tweet contains the same tweets but cleaned version\n",
        "data['clean_tweet'] = data['tweet']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_LAyTSsEd2F"
      },
      "source": [
        "# Changing all the tweets into lowercase \n",
        "data['clean_tweet'] =data['clean_tweet'].apply(lambda x: x.lower())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crXK7zNaEd2J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0adbc9d3-09f5-428f-bd89-db2868e7c65e"
      },
      "source": [
        "pd.options.display.max_colwidth=200\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>existence</th>\n",
              "      <th>confidence</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming report urges governments to act|brussels, belgium (ap) - the world faces increased hunger and .. [link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fighting poverty and global warming in Africa [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>fighting poverty and global warming in africa [link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carbon offsets: How a Vatican forest failed to reduce global warming [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>carbon offsets: how a vatican forest failed to reduce global warming [link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carbon offsets: How a Vatican forest failed to reduce global warming [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>carbon offsets: how a vatican forest failed to reduce global warming [link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8087</td>\n",
              "      <td>uruguay: tools needed for those most vulnerable to climate change [link]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                    tweet  ...                                                                                                             clean_tweet\n",
              "0  Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. [link]  ...  global warming report urges governments to act|brussels, belgium (ap) - the world faces increased hunger and .. [link]\n",
              "1                                                                    Fighting poverty and global warming in Africa [link]  ...                                                                    fighting poverty and global warming in africa [link]\n",
              "2                                             Carbon offsets: How a Vatican forest failed to reduce global warming [link]  ...                                             carbon offsets: how a vatican forest failed to reduce global warming [link]\n",
              "3                                             Carbon offsets: How a Vatican forest failed to reduce global warming [link]  ...                                             carbon offsets: how a vatican forest failed to reduce global warming [link]\n",
              "4                                                URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change [link]  ...                                                uruguay: tools needed for those most vulnerable to climate change [link]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESJI3HfeEd2K"
      },
      "source": [
        "# Removing \"@user\" from all the tweets\n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "    return input_txt\n",
        "\n",
        "# remove twitter handles (@user)\n",
        "data['clean_tweet'] = np.vectorize(remove_pattern)(data['clean_tweet'], \"@[\\w]*\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOFlYAtBEd2M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2f43efb7-579f-435a-b55a-ae084a354748"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>existence</th>\n",
              "      <th>confidence</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Global warming report urges governments to act...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming report urges governments to act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fighting poverty and global warming in Africa ...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>fighting poverty and global warming in africa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>carbon offsets: how a vatican forest failed to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>carbon offsets: how a vatican forest failed to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8087</td>\n",
              "      <td>uruguay: tools needed for those most vulnerabl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  ...                                        clean_tweet\n",
              "0  Global warming report urges governments to act...  ...  global warming report urges governments to act...\n",
              "1  Fighting poverty and global warming in Africa ...  ...  fighting poverty and global warming in africa ...\n",
              "2  Carbon offsets: How a Vatican forest failed to...  ...  carbon offsets: how a vatican forest failed to...\n",
              "3  Carbon offsets: How a Vatican forest failed to...  ...  carbon offsets: how a vatican forest failed to...\n",
              "4  URUGUAY: Tools Needed for Those Most Vulnerabl...  ...  uruguay: tools needed for those most vulnerabl...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq9RMq4GOLbe",
        "outputId": "470ff3b8-c8a4-45f3-a853-fdd16ae8c5e0"
      },
      "source": [
        "#Removing links \r\n",
        "\r\n",
        "#data['clean_tweet'] =data['clean_tweet'].apply(lambda x : re.sub(r'[https?:\\/\\/]',' ',x))\r\n",
        "#r'https?://\\S+'\r\n",
        "#(https?:\\/\\/)\r\n",
        "pd.options.display.max_colwidth=200\r\n",
        "data['clean_tweet'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         global warming re or  urge  governmen    o ac |bru  el , belgium (a ) -   e world face  increa ed  unger and .. [link]\n",
              "1                                                                           fig  ing  over y and global warming in africa [link]\n",
              "2                                                    carbon off e     ow a va ican fore   failed  o reduce global warming [link]\n",
              "3                                                    carbon off e     ow a va ican fore   failed  o reduce global warming [link]\n",
              "4                                                       uruguay   ool  needed for   o e mo   vulnerable  o clima e c ange [link]\n",
              "5                                          r    r    ocean  al ine     ow  global warming i  in en ifying our wa er cycle [link]\n",
              "6         global warming evidence all around u |a me  age  o global warming denier  and doub er   ju   look around our .. [link]\n",
              "7                                                                 migra ory bird ' new clima e c ange   ra egy    ay  ome [link]\n",
              "8                 ou  ern africa  com e ing for lim o o wa er  clima e c ange will bring  ig er  em era ure   o  ou  e... [link]\n",
              "9    global warming  o im ac  w ea , rice  roduc ion in india|lud iana, a r 18    carci y of wa er will  ave a  eriou  .. [link]\n",
              "Name: clean_tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJjD5PeCEd2O"
      },
      "source": [
        "#Replacing Special Characters with space\n",
        "data['clean_tweet'] =data['clean_tweet'].apply(lambda x: re.sub(r'[^a-zA-Z]',' ',x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcj9eyG8Ed2Q"
      },
      "source": [
        "#Replacing Punctuations with space\n",
        "data['clean_tweet'] =data['clean_tweet'].apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "0W6wr4NRtep4",
        "outputId": "91c24e06-f678-4410-c2bf-a16203073d84"
      },
      "source": [
        "pd.options.display.max_colwidth=200\r\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>existence</th>\n",
              "      <th>confidence</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming re or  urge  governmen    o ac  bru  el   belgium  a       e world face  increa ed  unger and     link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fighting poverty and global warming in Africa [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>fig  ing  over y and global warming in africa  link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carbon offsets: How a Vatican forest failed to reduce global warming [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>carbon off e     ow a va ican fore   failed  o reduce global warming  link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carbon offsets: How a Vatican forest failed to reduce global warming [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>carbon off e     ow a va ican fore   failed  o reduce global warming  link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8087</td>\n",
              "      <td>uruguay   ool  needed for   o e mo   vulnerable  o clima e c ange  link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @sejorg: RT @JaymiHeimbuch: Ocean Saltiness Shows Global Warming Is Intensifying Our Water Cycle [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>r    r    ocean  al ine     ow  global warming i  in en ifying our wa er cycle  link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Global warming evidence all around us|A message to global warming deniers and doubters: Just look around our .. [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming evidence all around u  a me  age  o global warming denier  and doub er   ju   look around our     link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Migratory Birds' New Climate Change Strategy: Stay Home [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>migra ory bird   new clima e c ange   ra egy    ay  ome  link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Southern Africa: Competing for Limpopo Water: Climate change will bring higher temperatures to Southe... [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>ou  ern africa  com e ing for lim o o wa er  clima e c ange will bring  ig er  em era ure   o  ou  e     link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Global warming to impact wheat, rice production in India|Ludhiana, Apr 18 : Scarcity of water will have a serious .. [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming  o im ac  w ea   rice  roduc ion in india lud iana  a r       carci y of wa er will  ave a  eriou      link</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                         tweet  ...                                                                                                                  clean_tweet\n",
              "0       Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. [link]  ...       global warming re or  urge  governmen    o ac  bru  el   belgium  a       e world face  increa ed  unger and     link \n",
              "1                                                                         Fighting poverty and global warming in Africa [link]  ...                                                                         fig  ing  over y and global warming in africa  link \n",
              "2                                                  Carbon offsets: How a Vatican forest failed to reduce global warming [link]  ...                                                  carbon off e     ow a va ican fore   failed  o reduce global warming  link \n",
              "3                                                  Carbon offsets: How a Vatican forest failed to reduce global warming [link]  ...                                                  carbon off e     ow a va ican fore   failed  o reduce global warming  link \n",
              "4                                                     URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change [link]  ...                                                     uruguay   ool  needed for   o e mo   vulnerable  o clima e c ange  link \n",
              "5                   RT @sejorg: RT @JaymiHeimbuch: Ocean Saltiness Shows Global Warming Is Intensifying Our Water Cycle [link]  ...                                        r    r    ocean  al ine     ow  global warming i  in en ifying our wa er cycle  link \n",
              "6       Global warming evidence all around us|A message to global warming deniers and doubters: Just look around our .. [link]  ...       global warming evidence all around u  a me  age  o global warming denier  and doub er   ju   look around our     link \n",
              "7                                                               Migratory Birds' New Climate Change Strategy: Stay Home [link]  ...                                                               migra ory bird   new clima e c ange   ra egy    ay  ome  link \n",
              "8              Southern Africa: Competing for Limpopo Water: Climate change will bring higher temperatures to Southe... [link]  ...               ou  ern africa  com e ing for lim o o wa er  clima e c ange will bring  ig er  em era ure   o  ou  e     link \n",
              "9  Global warming to impact wheat, rice production in India|Ludhiana, Apr 18 : Scarcity of water will have a serious .. [link]  ...  global warming  o im ac  w ea   rice  roduc ion in india lud iana  a r       carci y of wa er will  ave a  eriou      link \n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4mr6Dm7KSUv"
      },
      "source": [
        "# Importing stop words from NLTK corpus and word tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4txP4X6Ed2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a1ea1d-5792-4eba-cd9c-901b913b4884"
      },
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63kEsIwEd2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c21a2d-336b-437a-ef78-8a06fc029d97"
      },
      "source": [
        "# Importing stop words from NLTK corpus for english language\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBB8A2uRKZcn"
      },
      "source": [
        "# Creating token for the clean tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh-sHDjxEd2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f662d931-5170-4884-8bd5-96d8adb9627e"
      },
      "source": [
        "\n",
        "data['tweet_token']=data['clean_tweet']\n",
        "data['tweet_token']=data['clean_tweet'].apply(lambda x: word_tokenize(x))\n",
        "data['tweet_token'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  [global, warming, re, or, urge, governmen, o, ac, bru, el, belgium, a, e, world, face, increa, ed, unger, and, link]\n",
              "1                                                                           [fig, ing, over, y, and, global, warming, in, africa, link]\n",
              "2                                                     [carbon, off, e, ow, a, va, ican, fore, failed, o, reduce, global, warming, link]\n",
              "3                                                     [carbon, off, e, ow, a, va, ican, fore, failed, o, reduce, global, warming, link]\n",
              "4                                                         [uruguay, ool, needed, for, o, e, mo, vulnerable, o, clima, e, c, ange, link]\n",
              "5                                              [r, r, ocean, al, ine, ow, global, warming, i, in, en, ifying, our, wa, er, cycle, link]\n",
              "6       [global, warming, evidence, all, around, u, a, me, age, o, global, warming, denier, and, doub, er, ju, look, around, our, link]\n",
              "7                                                                    [migra, ory, bird, new, clima, e, c, ange, ra, egy, ay, ome, link]\n",
              "8          [ou, ern, africa, com, e, ing, for, lim, o, o, wa, er, clima, e, c, ange, will, bring, ig, er, em, era, ure, o, ou, e, link]\n",
              "9    [global, warming, o, im, ac, w, ea, rice, roduc, ion, in, india, lud, iana, a, r, carci, y, of, wa, er, will, ave, a, eriou, link]\n",
              "Name: tweet_token, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87tXTQwFKiH0"
      },
      "source": [
        "#Removing Stopwords\r\n",
        "# Created new columns of tokens - where stop words are being removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNTFY2Z3Ed2V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "a59da95e-95f1-454f-e628-1a41a91914bc"
      },
      "source": [
        "\n",
        "data['tweet_token_filtered'] =data['tweet_token'].apply(lambda x: [word for word in x if not word in stop_words])\n",
        "\n",
        "## Tokens columns with stop words and without stop words\n",
        "data[['tweet_token', 'tweet_token_filtered']].head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[global, warming, re, or, urge, governmen, o, ac, bru, el, belgium, a, e, world, face, increa, ed, unger, and, link]</td>\n",
              "      <td>[global, warming, urge, governmen, ac, bru, el, belgium, e, world, face, increa, ed, unger, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[fig, ing, over, y, and, global, warming, in, africa, link]</td>\n",
              "      <td>[fig, ing, global, warming, africa, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[carbon, off, e, ow, a, va, ican, fore, failed, o, reduce, global, warming, link]</td>\n",
              "      <td>[carbon, e, ow, va, ican, fore, failed, reduce, global, warming, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[carbon, off, e, ow, a, va, ican, fore, failed, o, reduce, global, warming, link]</td>\n",
              "      <td>[carbon, e, ow, va, ican, fore, failed, reduce, global, warming, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[uruguay, ool, needed, for, o, e, mo, vulnerable, o, clima, e, c, ange, link]</td>\n",
              "      <td>[uruguay, ool, needed, e, mo, vulnerable, clima, e, c, ange, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[r, r, ocean, al, ine, ow, global, warming, i, in, en, ifying, our, wa, er, cycle, link]</td>\n",
              "      <td>[r, r, ocean, al, ine, ow, global, warming, en, ifying, wa, er, cycle, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[global, warming, evidence, all, around, u, a, me, age, o, global, warming, denier, and, doub, er, ju, look, around, our, link]</td>\n",
              "      <td>[global, warming, evidence, around, u, age, global, warming, denier, doub, er, ju, look, around, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[migra, ory, bird, new, clima, e, c, ange, ra, egy, ay, ome, link]</td>\n",
              "      <td>[migra, ory, bird, new, clima, e, c, ange, ra, egy, ay, ome, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[ou, ern, africa, com, e, ing, for, lim, o, o, wa, er, clima, e, c, ange, will, bring, ig, er, em, era, ure, o, ou, e, link]</td>\n",
              "      <td>[ou, ern, africa, com, e, ing, lim, wa, er, clima, e, c, ange, bring, ig, er, em, era, ure, ou, e, link]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[global, warming, o, im, ac, w, ea, rice, roduc, ion, in, india, lud, iana, a, r, carci, y, of, wa, er, will, ave, a, eriou, link]</td>\n",
              "      <td>[global, warming, im, ac, w, ea, rice, roduc, ion, india, lud, iana, r, carci, wa, er, ave, eriou, link]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                          tweet_token                                                                                      tweet_token_filtered\n",
              "0                [global, warming, re, or, urge, governmen, o, ac, bru, el, belgium, a, e, world, face, increa, ed, unger, and, link]         [global, warming, urge, governmen, ac, bru, el, belgium, e, world, face, increa, ed, unger, link]\n",
              "1                                                                         [fig, ing, over, y, and, global, warming, in, africa, link]                                                                 [fig, ing, global, warming, africa, link]\n",
              "2                                                   [carbon, off, e, ow, a, va, ican, fore, failed, o, reduce, global, warming, link]                                    [carbon, e, ow, va, ican, fore, failed, reduce, global, warming, link]\n",
              "3                                                   [carbon, off, e, ow, a, va, ican, fore, failed, o, reduce, global, warming, link]                                    [carbon, e, ow, va, ican, fore, failed, reduce, global, warming, link]\n",
              "4                                                       [uruguay, ool, needed, for, o, e, mo, vulnerable, o, clima, e, c, ange, link]                                        [uruguay, ool, needed, e, mo, vulnerable, clima, e, c, ange, link]\n",
              "5                                            [r, r, ocean, al, ine, ow, global, warming, i, in, en, ifying, our, wa, er, cycle, link]                              [r, r, ocean, al, ine, ow, global, warming, en, ifying, wa, er, cycle, link]\n",
              "6     [global, warming, evidence, all, around, u, a, me, age, o, global, warming, denier, and, doub, er, ju, look, around, our, link]    [global, warming, evidence, around, u, age, global, warming, denier, doub, er, ju, look, around, link]\n",
              "7                                                                  [migra, ory, bird, new, clima, e, c, ange, ra, egy, ay, ome, link]                                        [migra, ory, bird, new, clima, e, c, ange, ra, egy, ay, ome, link]\n",
              "8        [ou, ern, africa, com, e, ing, for, lim, o, o, wa, er, clima, e, c, ange, will, bring, ig, er, em, era, ure, o, ou, e, link]  [ou, ern, africa, com, e, ing, lim, wa, er, clima, e, c, ange, bring, ig, er, em, era, ure, ou, e, link]\n",
              "9  [global, warming, o, im, ac, w, ea, rice, roduc, ion, in, india, lud, iana, a, r, carci, y, of, wa, er, will, ave, a, eriou, link]  [global, warming, im, ac, w, ea, rice, roduc, ion, india, lud, iana, r, carci, wa, er, ave, eriou, link]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx6cDihdKsOx"
      },
      "source": [
        "#Lemmatizing tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkUtU0hXEd2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15464eac-7edd-454b-e8ef-595ef2941b75"
      },
      "source": [
        "# Importing library for lemmatizing\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lemmatizing = WordNetLemmatizer()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k1F1T2AEd2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "213c4a6c-7342-4f03-b3f5-aee8b7a1ce68"
      },
      "source": [
        "# Created one more columns tweet_lemmatized it shows tweets' lemmatized version\n",
        "data['tweet_lemmatized'] = data['clean_tweet']\n",
        "\n",
        "data['tweet_lemmatized']=data['tweet_token'].apply(lambda x: ' '.join([lemmatizing.lemmatize(i) for i in x]))\n",
        "data['tweet_lemmatized'].head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0              global warming re or urge governmen o ac bru el belgium a e world face increa ed unger and link\n",
              "1                                                             fig ing over y and global warming in africa link\n",
              "2                                           carbon off e ow a va ican fore failed o reduce global warming link\n",
              "3                                           carbon off e ow a va ican fore failed o reduce global warming link\n",
              "4                                               uruguay ool needed for o e mo vulnerable o clima e c ange link\n",
              "5                                       r r ocean al ine ow global warming i in en ifying our wa er cycle link\n",
              "6    global warming evidence all around u a me age o global warming denier and doub er ju look around our link\n",
              "7                                                         migra ory bird new clima e c ange ra egy ay ome link\n",
              "8             ou ern africa com e ing for lim o o wa er clima e c ange will bring ig er em era ure o ou e link\n",
              "9      global warming o im ac w ea rice roduc ion in india lud iana a r carci y of wa er will ave a eriou link\n",
              "Name: tweet_lemmatized, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F9w9wa-Kzyc"
      },
      "source": [
        "#Stemming Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h36bZlj7Ed2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "14f24326-67c8-4878-a8f3-9f6420560236"
      },
      "source": [
        "# Importing library for stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "stemming = PorterStemmer()\n",
        "# Created one more columns tweet_stemmed it shows tweets' stemmed version\n",
        "data['tweet_stemmed'] = data['clean_tweet']\n",
        "\n",
        "data['tweet_stemmed'] =data['tweet_token'].apply(lambda x: ' '.join([stemming.stem(i) for i in x]))\n",
        "\n",
        "data[['tweet_stemmed', 'tweet_lemmatized']].tail(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6078</th>\n",
              "      <td>ba bird and lizard can fig clima e c ang bird ba and lizard may lay an im or an role in ear cl ow ly qg</td>\n",
              "      <td>ba bird and lizard can fig clima e c ange bird ba and lizard may lay an im or an role in ear cl ow ly qg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6079</th>\n",
              "      <td>ba bird and lizard can fig clima e c ang bird ba and lizard may lay an im or an role in ear cl ow ly ql</td>\n",
              "      <td>ba bird and lizard can fig clima e c ange bird ba and lizard may lay an im or an role in ear cl ow ly ql</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6080</th>\n",
              "      <td>ba bird and lizard can fig clima e c ang bird ba and lizard may lay an im or an role in ear cl ow ly qk</td>\n",
              "      <td>ba bird and lizard can fig clima e c ange bird ba and lizard may lay an im or an role in ear cl ow ly qk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6081</th>\n",
              "      <td>ba bird and lizard can fig clima e c ang bird ba and lizard may lay an im or an role in ear cl ow ly qi</td>\n",
              "      <td>ba bird and lizard can fig clima e c ange bird ba and lizard may lay an im or an role in ear cl ow ly qi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6082</th>\n",
              "      <td>global warm e fo il fuel dilemma america u e abou million barrel er oil eac day o erv e need bi ly aeoud</td>\n",
              "      <td>global warming e fo il fuel dilemma america u e abou million barrel er oil eac day o erve e need bi ly aeoud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6084</th>\n",
              "      <td>i and climb in nyc augu wea er for e fir day of may unbeliev c alk i u o global warm</td>\n",
              "      <td>i and climbing in nyc augu wea er for e fir day of may unbelievable c alk i u o global warming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6085</th>\n",
              "      <td>e ra e global warm ould be abandon in favor of clima e c ang lun z ay bi ly biy c co</td>\n",
              "      <td>e ra e global warming ould be abandoned in favor of clima e c ange lun z ay bi ly biy c co</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6087</th>\n",
              "      <td>global warm you ube arodi you will enjoy i cc ocra bi ly bbgw c</td>\n",
              "      <td>global warming you ube arody you will enjoy i cc ocra bi ly bbgw c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6088</th>\n",
              "      <td>one eye golfer don dare ell me abou global warm wen y five of e for y nine golfer make e cu i bi ly akeax</td>\n",
              "      <td>one eyed golfer don dare ell me abou global warming wen y five of e for y nine golfer making e cu i bi ly akeax</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6089</th>\n",
              "      <td>man made global warm a air brain eori e cien ific c alleng e i c a no ing o back u claim co clima ega e</td>\n",
              "      <td>man made global warming a air brained eory e cien ifically c allenged e i c a no ing o back u claim co clima ega e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                  tweet_stemmed                                                                                                    tweet_lemmatized\n",
              "6078    ba bird and lizard can fig clima e c ang bird ba and lizard may lay an im or an role in ear cl ow ly qg            ba bird and lizard can fig clima e c ange bird ba and lizard may lay an im or an role in ear cl ow ly qg\n",
              "6079    ba bird and lizard can fig clima e c ang bird ba and lizard may lay an im or an role in ear cl ow ly ql            ba bird and lizard can fig clima e c ange bird ba and lizard may lay an im or an role in ear cl ow ly ql\n",
              "6080    ba bird and lizard can fig clima e c ang bird ba and lizard may lay an im or an role in ear cl ow ly qk            ba bird and lizard can fig clima e c ange bird ba and lizard may lay an im or an role in ear cl ow ly qk\n",
              "6081    ba bird and lizard can fig clima e c ang bird ba and lizard may lay an im or an role in ear cl ow ly qi            ba bird and lizard can fig clima e c ange bird ba and lizard may lay an im or an role in ear cl ow ly qi\n",
              "6082   global warm e fo il fuel dilemma america u e abou million barrel er oil eac day o erv e need bi ly aeoud        global warming e fo il fuel dilemma america u e abou million barrel er oil eac day o erve e need bi ly aeoud\n",
              "6084                       i and climb in nyc augu wea er for e fir day of may unbeliev c alk i u o global warm                      i and climbing in nyc augu wea er for e fir day of may unbelievable c alk i u o global warming\n",
              "6085                       e ra e global warm ould be abandon in favor of clima e c ang lun z ay bi ly biy c co                          e ra e global warming ould be abandoned in favor of clima e c ange lun z ay bi ly biy c co\n",
              "6087                                            global warm you ube arodi you will enjoy i cc ocra bi ly bbgw c                                                  global warming you ube arody you will enjoy i cc ocra bi ly bbgw c\n",
              "6088  one eye golfer don dare ell me abou global warm wen y five of e for y nine golfer make e cu i bi ly akeax     one eyed golfer don dare ell me abou global warming wen y five of e for y nine golfer making e cu i bi ly akeax\n",
              "6089    man made global warm a air brain eori e cien ific c alleng e i c a no ing o back u claim co clima ega e  man made global warming a air brained eory e cien ifically c allenged e i c a no ing o back u claim co clima ega e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdUNfUnr_I_u"
      },
      "source": [
        "#Adding Labels to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMtcpJ5FBAuY",
        "outputId": "43d4a1ec-fd6a-417b-b3db-d3ea90a49c76"
      },
      "source": [
        "# LABEL THE DATA BEFORE MODELLING IT\r\n",
        "!pip install textblob    #needed for sentiment analysis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "rdigbceiCHr0",
        "outputId": "5acf4c3f-530e-48d6-c6ff-474f89313f26"
      },
      "source": [
        "from textblob import TextBlob\r\n",
        "data['sentiment'] = data['tweet'].apply(lambda Tweet: TextBlob(Tweet).sentiment.polarity)\r\n",
        "pd.options.display.max_colwidth=200\r\n",
        "data.head()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>existence</th>\n",
              "      <th>confidence</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming re or  urge  governmen    o ac  bru  el   belgium  a       e world face  increa ed  unger and     link</td>\n",
              "      <td>[global, warming, re, or, urge, governmen, o, ac, bru, el, belgium, a, e, world, face, increa, ed, unger, and, link]</td>\n",
              "      <td>[global, warming, urge, governmen, ac, bru, el, belgium, e, world, face, increa, ed, unger, link]</td>\n",
              "      <td>global warming re or urge governmen o ac bru el belgium a e world face increa ed unger and link</td>\n",
              "      <td>global warm re or urg governmen o ac bru el belgium a e world face increa ed unger and link</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fighting poverty and global warming in Africa [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>fig  ing  over y and global warming in africa  link</td>\n",
              "      <td>[fig, ing, over, y, and, global, warming, in, africa, link]</td>\n",
              "      <td>[fig, ing, global, warming, africa, link]</td>\n",
              "      <td>fig ing over y and global warming in africa link</td>\n",
              "      <td>fig ing over y and global warm in africa link</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carbon offsets: How a Vatican forest failed to reduce global warming [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>carbon off e     ow a va ican fore   failed  o reduce global warming  link</td>\n",
              "      <td>[carbon, off, e, ow, a, va, ican, fore, failed, o, reduce, global, warming, link]</td>\n",
              "      <td>[carbon, e, ow, va, ican, fore, failed, reduce, global, warming, link]</td>\n",
              "      <td>carbon off e ow a va ican fore failed o reduce global warming link</td>\n",
              "      <td>carbon off e ow a va ican fore fail o reduc global warm link</td>\n",
              "      <td>-0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carbon offsets: How a Vatican forest failed to reduce global warming [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>carbon off e     ow a va ican fore   failed  o reduce global warming  link</td>\n",
              "      <td>[carbon, off, e, ow, a, va, ican, fore, failed, o, reduce, global, warming, link]</td>\n",
              "      <td>[carbon, e, ow, va, ican, fore, failed, reduce, global, warming, link]</td>\n",
              "      <td>carbon off e ow a va ican fore failed o reduce global warming link</td>\n",
              "      <td>carbon off e ow a va ican fore fail o reduc global warm link</td>\n",
              "      <td>-0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change [link]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8087</td>\n",
              "      <td>uruguay   ool  needed for   o e mo   vulnerable  o clima e c ange  link</td>\n",
              "      <td>[uruguay, ool, needed, for, o, e, mo, vulnerable, o, clima, e, c, ange, link]</td>\n",
              "      <td>[uruguay, ool, needed, e, mo, vulnerable, clima, e, c, ange, link]</td>\n",
              "      <td>uruguay ool needed for o e mo vulnerable o clima e c ange link</td>\n",
              "      <td>uruguay ool need for o e mo vulner o clima e c ang link</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                    tweet  ... sentiment\n",
              "0  Global warming report urges governments to act|BRUSSELS, Belgium (AP) - The world faces increased hunger and .. [link]  ...      0.00\n",
              "1                                                                    Fighting poverty and global warming in Africa [link]  ...      0.00\n",
              "2                                             Carbon offsets: How a Vatican forest failed to reduce global warming [link]  ...     -0.25\n",
              "3                                             Carbon offsets: How a Vatican forest failed to reduce global warming [link]  ...     -0.25\n",
              "4                                                URUGUAY: Tools Needed for Those Most Vulnerable to Climate Change [link]  ...      0.00\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7p76zJqC8Q6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "84f4ba4f-e5c5-4f49-e751-afd4150afc96"
      },
      "source": [
        "#Finally adding labels \r\n",
        "import numpy as np\r\n",
        "conditionList = [\r\n",
        "     data['sentiment'] ==0,            \r\n",
        "    data['sentiment'] > 0.0,\r\n",
        "    data['sentiment'] < 0.0]\r\n",
        "choiceList = ['neutral','positive', 'negative']\r\n",
        "data['label'] = np.select(conditionList, choiceList, default='no_label')\r\n",
        "pd.options.display.max_colwidth=20\r\n",
        "data.head(20)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>existence</th>\n",
              "      <th>confidence</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Global warming r...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming r...</td>\n",
              "      <td>[global, warming...</td>\n",
              "      <td>[global, warming...</td>\n",
              "      <td>global warming r...</td>\n",
              "      <td>global warm re o...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fighting poverty...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>fig  ing  over y...</td>\n",
              "      <td>[fig, ing, over,...</td>\n",
              "      <td>[fig, ing, globa...</td>\n",
              "      <td>fig ing over y a...</td>\n",
              "      <td>fig ing over y a...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carbon offsets: ...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>carbon off e    ...</td>\n",
              "      <td>[carbon, off, e,...</td>\n",
              "      <td>[carbon, e, ow, ...</td>\n",
              "      <td>carbon off e ow ...</td>\n",
              "      <td>carbon off e ow ...</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carbon offsets: ...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>carbon off e    ...</td>\n",
              "      <td>[carbon, off, e,...</td>\n",
              "      <td>[carbon, e, ow, ...</td>\n",
              "      <td>carbon off e ow ...</td>\n",
              "      <td>carbon off e ow ...</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>URUGUAY: Tools N...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8087</td>\n",
              "      <td>uruguay   ool  n...</td>\n",
              "      <td>[uruguay, ool, n...</td>\n",
              "      <td>[uruguay, ool, n...</td>\n",
              "      <td>uruguay ool need...</td>\n",
              "      <td>uruguay ool need...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @sejorg: RT @...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>r    r    ocean ...</td>\n",
              "      <td>[r, r, ocean, al...</td>\n",
              "      <td>[r, r, ocean, al...</td>\n",
              "      <td>r r ocean al ine...</td>\n",
              "      <td>r r ocean al ine...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Global warming e...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming e...</td>\n",
              "      <td>[global, warming...</td>\n",
              "      <td>[global, warming...</td>\n",
              "      <td>global warming e...</td>\n",
              "      <td>global warm evid...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Migratory Birds'...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>migra ory bird  ...</td>\n",
              "      <td>[migra, ory, bir...</td>\n",
              "      <td>[migra, ory, bir...</td>\n",
              "      <td>migra ory bird n...</td>\n",
              "      <td>migra ori bird n...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Southern Africa:...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>ou  ern africa ...</td>\n",
              "      <td>[ou, ern, africa...</td>\n",
              "      <td>[ou, ern, africa...</td>\n",
              "      <td>ou ern africa co...</td>\n",
              "      <td>ou ern africa co...</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Global warming t...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming  ...</td>\n",
              "      <td>[global, warming...</td>\n",
              "      <td>[global, warming...</td>\n",
              "      <td>global warming o...</td>\n",
              "      <td>global warm o im...</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do we solve ...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.9073</td>\n",
              "      <td>ow do we  olve ...</td>\n",
              "      <td>[ow, do, we, olv...</td>\n",
              "      <td>[ow, olve, globa...</td>\n",
              "      <td>ow do we olve i ...</td>\n",
              "      <td>ow do we olv i g...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Blog|A prelimina...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>blog a  relimina...</td>\n",
              "      <td>[blog, a, relimi...</td>\n",
              "      <td>[blog, reliminar...</td>\n",
              "      <td>blog a reliminar...</td>\n",
              "      <td>blog a reliminar...</td>\n",
              "      <td>0.106667</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Ecotone: #Climat...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.5488</td>\n",
              "      <td>eco one   clima ...</td>\n",
              "      <td>[eco, one, clima...</td>\n",
              "      <td>[eco, one, clima...</td>\n",
              "      <td>eco one clima e ...</td>\n",
              "      <td>eco one clima e ...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Climate change b...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.8823</td>\n",
              "      <td>clima e c ange b...</td>\n",
              "      <td>[clima, e, c, an...</td>\n",
              "      <td>[clima, e, c, an...</td>\n",
              "      <td>clima e c ange b...</td>\n",
              "      <td>clima e c ang bl...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Government Repor...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>governmen  re or...</td>\n",
              "      <td>[governmen, re, ...</td>\n",
              "      <td>[governmen, ay, ...</td>\n",
              "      <td>governmen re or ...</td>\n",
              "      <td>governmen re or ...</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>For #EarthDay Gl...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>for  ear  day gl...</td>\n",
              "      <td>[for, ear, day, ...</td>\n",
              "      <td>[ear, day, globa...</td>\n",
              "      <td>for ear day glob...</td>\n",
              "      <td>for ear day glob...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Wait here's an i...</td>\n",
              "      <td>No</td>\n",
              "      <td>0.6648</td>\n",
              "      <td>wai   ere   an i...</td>\n",
              "      <td>[wai, ere, an, i...</td>\n",
              "      <td>[wai, ere, idea,...</td>\n",
              "      <td>wai ere an idea ...</td>\n",
              "      <td>wai ere an idea ...</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>EPA issues repor...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>e a i  ue  re or...</td>\n",
              "      <td>[e, a, i, ue, re...</td>\n",
              "      <td>[e, ue, u, clima...</td>\n",
              "      <td>e a i ue re or o...</td>\n",
              "      <td>e a i ue re or o...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>QUT researchers ...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.5194</td>\n",
              "      <td>qu  re earc er  ...</td>\n",
              "      <td>[qu, re, earc, e...</td>\n",
              "      <td>[qu, earc, er, r...</td>\n",
              "      <td>qu re earc er ra...</td>\n",
              "      <td>qu re earc er ra...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Global Warming: ...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>global warming  ...</td>\n",
              "      <td>[global, warming...</td>\n",
              "      <td>[global, warming...</td>\n",
              "      <td>global warming o...</td>\n",
              "      <td>global warm ocea...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  tweet existence  ...  sentiment     label\n",
              "0   Global warming r...       Yes  ...   0.000000   neutral\n",
              "1   Fighting poverty...       Yes  ...   0.000000   neutral\n",
              "2   Carbon offsets: ...       Yes  ...  -0.250000  negative\n",
              "3   Carbon offsets: ...       Yes  ...  -0.250000  negative\n",
              "4   URUGUAY: Tools N...       Yes  ...   0.000000   neutral\n",
              "5   RT @sejorg: RT @...       Yes  ...   0.000000   neutral\n",
              "6   Global warming e...       Yes  ...   0.000000   neutral\n",
              "7   Migratory Birds'...       Yes  ...   0.136364  positive\n",
              "8   Southern Africa:...       Yes  ...   0.125000  positive\n",
              "9   Global warming t...       Yes  ...  -0.166667  negative\n",
              "10  How do we solve ...       Yes  ...   0.000000   neutral\n",
              "11  Blog|A prelimina...       Yes  ...   0.106667  positive\n",
              "12  Ecotone: #Climat...       Yes  ...   0.000000   neutral\n",
              "13  Climate change b...       Yes  ...   0.000000   neutral\n",
              "15  Government Repor...       Yes  ...  -0.050000  negative\n",
              "16  For #EarthDay Gl...       Yes  ...   0.000000   neutral\n",
              "17  Wait here's an i...        No  ...   0.033333  positive\n",
              "18  EPA issues repor...       Yes  ...   0.000000   neutral\n",
              "19  QUT researchers ...       Yes  ...   0.000000   neutral\n",
              "20  Global Warming: ...       Yes  ...   0.000000   neutral\n",
              "\n",
              "[20 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY_rGKtVjLij"
      },
      "source": [
        "#Extracting Features from Cleaned Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "632QK9nxjQnS"
      },
      "source": [
        "#Bag-of-Words Model-Stemmed Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-7xihLZDUbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c852d5-b565-4c64-af1a-20cf1eef8861"
      },
      "source": [
        "# Importing library\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, stop_words='english')\r\n",
        "bow_vectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=0.9, max_features=None, min_df=2,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHsq7-llknlZ",
        "outputId": "45b11f97-7a16-465d-e6f0-98afd5a5e276"
      },
      "source": [
        "# bag-of-words feature matrix - For columns \"combine_df['tweet_stemmed']\"\r\n",
        "bow_stem = bow_vectorizer.fit_transform(data['tweet_stemmed'])\r\n",
        "bow_stem"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4134x2546 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 49515 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fA-bJUUlB7v"
      },
      "source": [
        "# Model Building: Twitter Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2bYc1iUgnS_"
      },
      "source": [
        "#Stemmed tweets models ahead- Logistic Regression,Naive Bayes,K Neighbors,Decision Tree \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGEJvenzRP4t"
      },
      "source": [
        "# For columns \"['tweet_stemmed']\"\r\n",
        "x = bow_stem[:,:]     #training \r\n",
        "y= data['sentiment'] #sentiment column coz it has numeric values of label \r\n",
        "# splitting data into training and validation set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.2)\r\n",
        "\r\n",
        "lreg = LogisticRegression()\r\n",
        "lreg.fit(x_train, y_train) # training the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX-vkSEFlAmF"
      },
      "source": [
        "# Importing Libraries\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N73DXO6lKN6"
      },
      "source": [
        "Building model using Bag-of-Words features\r\n",
        "For columns ['tweet_stemmed']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5ygU-oOlSc1"
      },
      "source": [
        "# For columns \"['tweet_stemmed']\"\r\n",
        "x = bow_stem[:,:]     #training \r\n",
        "y= data['sentiment'] #sentiment column coz it has numeric values of label \r\n",
        "#using label encoder to change label values to cat values so that log reg can pass them\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn import utils\r\n",
        "\r\n",
        "labelencoder = preprocessing.LabelEncoder()\r\n",
        "y =labelencoder.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4FI9aLTVWcY"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "argtuVzJqWYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8261129-9ecc-4e1e-9219-05a180038db5"
      },
      "source": [
        "# splitting data into training and validation set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.2)\r\n",
        "\r\n",
        "lreg = LogisticRegression()\r\n",
        "lreg.fit(x_train, y_train) # training the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQbnbfsmESjC",
        "outputId": "3aa8b24d-2b88-4988-c9bc-21c42eb58817"
      },
      "source": [
        "#evaluating\r\n",
        "# Predicting the Test set results\r\n",
        "\r\n",
        "prediction = lreg.predict(x_test) # predicting on the validation \r\n",
        "A1 = f1_score(y_test, prediction,average='micro') # calculating f1 score\r\n",
        "print(A1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6505441354292624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NdKshTnVFZd"
      },
      "source": [
        "NAIVE BAYES MODEL- Stemmed tweets\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqcA1lsYrDcS",
        "outputId": "3ed3d063-73b8-42c0-a7ed-d1525d77b0e8"
      },
      "source": [
        "# bag-of-words feature matrix - For columns \"combine_df['tweet_stemmed']\"\r\n",
        "bow_stem = bow_vectorizer.fit_transform(data['tweet_stemmed'])\r\n",
        "bow_stem\r\n",
        "#using label encoder to change label values to cat values so that log reg can pass them\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn import utils\r\n",
        "\r\n",
        "labelencoder = preprocessing.LabelEncoder()\r\n",
        "y =labelencoder.fit_transform(y)\r\n",
        "\r\n",
        "# splitting data into training and validation set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.2)\r\n",
        "\r\n",
        "# Training the Naive Bayes model on the Training set\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "classifier = MultinomialNB()\r\n",
        "\r\n",
        "#x_train=x_train.toarray() #to convert to a dense numpy array.\r\n",
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGDVFVKqJLG5"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "#x_test=x_test.toarray()                                       #to convert to a dense numpy array.\r\n",
        "y_pred = classifier.predict(x_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2fFHcRGJvQy",
        "outputId": "bedb14cd-993e-4f65-8e90-61de5a92c842"
      },
      "source": [
        "#Checking accuracy- NB class\r\n",
        "from sklearn.metrics import accuracy_score \r\n",
        "acc=accuracy_score(y_test, y_pred)\r\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4969770253929867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgoKjeRVrN6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51023c5e-5253-4578-ea8c-768d0d4bc228"
      },
      "source": [
        "#F1_SCORE\r\n",
        "\r\n",
        "\r\n",
        "y_pred= classifier.predict(x_test) # predicting on the validation set\r\n",
        "\r\n",
        "nb_stemm_f1_score= f1_score(y_test, y_pred,average='micro') # calculating f1 score\r\n",
        "print(nb_stemm_f1_score)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4969770253929867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKYTxb5Vg9tP"
      },
      "source": [
        "K-Neighbors Model- Stemmed tweets\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIdlSDzLhBfy",
        "outputId": "96b47d3c-c6af-4160-dd26-30b9e23f744a"
      },
      "source": [
        "# bag-of-words feature matrix - For column \"['tweet_stemmed']\"\r\n",
        "bow_stem = bow_vectorizer.fit_transform(data['tweet_stemmed'])\r\n",
        "bow_stem\r\n",
        "# For columns \"['tweet_stemmed']\"\r\n",
        "x = bow_stem[:,:]     #training \r\n",
        "y= data['sentiment'] #sentiment column coz it has numeric values of label \r\n",
        "\r\n",
        "#using label encoder to change label values to cat values so that clf can pass them\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn import utils\r\n",
        "labelencoder = preprocessing.LabelEncoder()\r\n",
        "y =labelencoder.fit_transform(y)\r\n",
        "\r\n",
        "# splitting data into training and validation set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.2)\r\n",
        "\r\n",
        "# Training the Naive Bayes model on the Training set\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "classifier = KNeighborsClassifier(n_neighbors=10,weights='distance',\r\n",
        "                                  algorithm='kd_tree',p=2,metric='minkowski')\r\n",
        "\r\n",
        "#x_train=x_train.toarray() #to convert to a dense numpy array.\r\n",
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                     weights='distance')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6kRxv1jhy8o",
        "outputId": "3268d4a9-9a9b-49a8-adc2-a69af6128faa"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "#x_test=x_test.toarray()                                       #to convert to a dense numpy array.\r\n",
        "y_pred = classifier.predict(x_test)\r\n",
        "KN_stemm_f1_score= f1_score(y_test, y_pred,average='micro') # calculating f1 score\r\n",
        "print(KN_stemm_f1_score)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5671100362756953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBH6hWMaiKzY"
      },
      "source": [
        "Decision Tree Model for stemmed tweets\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ2gbmDfiZHj",
        "outputId": "b859fafd-e08d-404c-9d71-be88bd4b4c57"
      },
      "source": [
        "# bag-of-words feature matrix - For column \"['tweet_stemmed']\"\r\n",
        "bow_stem = bow_vectorizer.fit_transform(data['tweet_stemmed'])\r\n",
        "bow_stem\r\n",
        "# For columns \"['tweet_stemmed']\"\r\n",
        "x = bow_stem[:,:]     #training \r\n",
        "y= data['sentiment'] #sentiment column coz it has numeric values of label \r\n",
        "\r\n",
        "#using label encoder to change label values to cat values so that clf can pass them\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn import utils\r\n",
        "labelencoder = preprocessing.LabelEncoder()\r\n",
        "y =labelencoder.fit_transform(y)\r\n",
        "\r\n",
        "# splitting data into training and validation set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.2)\r\n",
        "\r\n",
        "# Training the Naive Bayes model on the Training set\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "classifier = DecisionTreeClassifier(splitter='best',max_features=1500,random_state=42)\r\n",
        "\r\n",
        "\r\n",
        "#x_train=x_train.toarray() #to convert to a dense numpy array.\r\n",
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=1500, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=42, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LOwXuLoiZQQ",
        "outputId": "6a1d6678-ec6e-490c-fc03-5cce791ad043"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "#x_test=x_test.toarray()                                       #to convert to a dense numpy array.\r\n",
        "y_pred = classifier.predict(x_test)\r\n",
        "Decision_tree_stemm_f1_score= f1_score(y_test, y_pred,average='micro') # calculating f1 score\r\n",
        "print(Decision_tree_stemm_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6275695284159613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIEa0eaJjU8V"
      },
      "source": [
        "SVM MODEL FOR STEMMED TWEETS\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2Ru4eJ4j7al",
        "outputId": "26dd9824-c43c-4742-c20d-3105c5af7d74"
      },
      "source": [
        "# bag-of-words feature matrix - For columns \"combine_df['tweet_stemmed']\"\r\n",
        "bow_stem = bow_vectorizer.fit_transform(data['tweet_stemmed'])\r\n",
        "bow_stem\r\n",
        "# For columns \"['tweet_stemmed']\"\r\n",
        "x = bow_stem[:,:]     #training \r\n",
        "y= data['sentiment'] #sentiment column coz it has numeric values of label \r\n",
        "\r\n",
        "#using label encoder to change label values to cat values so that clf can pass them\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn import utils\r\n",
        "labelencoder = preprocessing.LabelEncoder()\r\n",
        "y =labelencoder.fit_transform(y)\r\n",
        "\r\n",
        "# splitting data into training and validation set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.2)\r\n",
        "\r\n",
        "# Training the Naive Bayes model on the Training set\r\n",
        "from sklearn.svm import SVC\r\n",
        "classifier = SVC(kernel='rbf',random_state=42)\r\n",
        "\r\n",
        "#x_train=x_train.toarray() #to convert to a dense numpy array.\r\n",
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUni-vAlj7i-",
        "outputId": "dc3ce42c-6bea-4b57-f5da-af6e79887d90"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "#x_test=x_test.toarray()                                       #to convert to a dense numpy array.\r\n",
        "y_pred = classifier.predict(x_test)\r\n",
        "SVM_stemm_f1_score= f1_score(y_test, y_pred,average='micro') # calculating f1 score\r\n",
        "print(SVM_stemm_f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.558645707376058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1GyVNKFgfgH"
      },
      "source": [
        "#Lemmatized Tweets Models ahead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfr59xqQLFZJ"
      },
      "source": [
        "#Building model using Bag-of-Words features For column ['tweet_lemmatized']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk_h3_KhK8tf",
        "outputId": "ba8b9cd4-b082-44f3-e352-a8db2d116f4a"
      },
      "source": [
        "# bag-of-words feature matrix - For column -['tweet_lemmatized']\r\n",
        "bow_lemm = bow_vectorizer.fit_transform(data['tweet_lemmatized'])\r\n",
        "bow_lemm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4134x2767 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 49288 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2mKA4L4LanR"
      },
      "source": [
        "# For columns lemm\r\n",
        "x = bow_lemm[:,:]     #training \r\n",
        "y= data['sentiment']\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eyUgGUzLmnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d278d32-281c-484e-e115-b508db042eb1"
      },
      "source": [
        "# splitting data into training and validation set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.2)\r\n",
        "\r\n",
        "#x_train=x_train.toarray()\r\n",
        "\r\n",
        "#using label encoder to change label values to cat values so that log reg can pass them\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn import utils\r\n",
        "\r\n",
        "labelencoder = preprocessing.LabelEncoder()\r\n",
        "y =labelencoder.fit_transform(y)\r\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([201, 201,  52, ..., 355, 201, 201])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSR_QNyskzAs"
      },
      "source": [
        "#Naive Bayes for lemm tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzErv2mnLwRn",
        "outputId": "1a02293d-771a-4003-f4ec-4713171ac70f"
      },
      "source": [
        "# Training the Naive Bayes model on the Training set\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "classifier = MultinomialNB()\r\n",
        "#x_train=x_train.toarray() #to convert to a dense numpy array.\r\n",
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW97XWmdL1VW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c21ab32-6465-4ef2-93bb-cbec97bafb92"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "\r\n",
        "#x_test=x_test.toarray()                                       #to convert to a dense numpy array.\r\n",
        "y_pred = classifier.predict(x_test)\r\n",
        "nb_lemm_f1_score = f1_score(y_test, y_pred,average='micro') # calculating f1 score\r\n",
        "print(nb_lemm_f1_score)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4873035066505441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gMHJtM1L98K",
        "outputId": "1f989d57-34e6-466e-8651-eb96fdba9749"
      },
      "source": [
        "# calculating f1 score\r\n",
        "A2 = f1_score(y_test, prediction[:827],average=None) \r\n",
        "print(A2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.32454361 0.3616     0.35074627]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ85T-DbiYQr",
        "outputId": "5c7ab8c3-fd72-466a-c919-5242c230069f"
      },
      "source": [
        "#checking acc of lemmatized tweets for nb\r\n",
        "from sklearn.metrics import accuracy_score \r\n",
        "acc=accuracy_score(y_test, prediction)\r\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6505441354292624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8o7O2g7jEog"
      },
      "source": [
        "#LOGISTIC REGRESSION FOR LEMMATIZED TWEETS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tvl4RJ8jJgM"
      },
      "source": [
        "# Importing Libraries\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTgunWFHjJnx"
      },
      "source": [
        "# For columns \"['tweet_lemmatized']\"\r\n",
        "x = bow_lemm[:,:]     #training \r\n",
        "y= data['sentiment'] #sentiment column coz it has numeric values of label \r\n",
        "\r\n",
        "#using label encoder to change label values to cat values so that log reg can pass them\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn import utils\r\n",
        "\r\n",
        "labelencoder = preprocessing.LabelEncoder()\r\n",
        "y =labelencoder.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTk-Qk2ajKVY"
      },
      "source": [
        "# splitting data into training and validation set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42, test_size=0.2)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hNTG_QpjKdS",
        "outputId": "4884c762-3e0d-4839-8a8b-0396ca701f99"
      },
      "source": [
        "lreg = LogisticRegression()\r\n",
        "lreg.fit(x_train, y_train) # training the model\r\n",
        "prediction = lreg.predict(x_test) # predicting on the validation set\r\n",
        "A1 = f1_score(y_test, prediction,average='micro') # calculating f1 score\r\n",
        "print(A1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6505441354292624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcAelgIskYIt",
        "outputId": "ee69573a-11a7-4d1a-b79b-ea90ffbe24f9"
      },
      "source": [
        "#Checking accuracy- log reg class for lemm tweets\r\n",
        "from sklearn.metrics import accuracy_score \r\n",
        "acc=accuracy_score(y_test,prediction)\r\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6505441354292624\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
ASHNA'S CODE ENDS HERE
